{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "318acc6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Libraries\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import cv2\n",
    "import os\n",
    "import glob\n",
    "\n",
    "import math \n",
    "import datetime\n",
    "import time\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras import layers, Input, Model\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.applications import ResNet50V2, VGG16\n",
    "from keras.utils.vis_utils import plot_model\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.initializers import glorot_uniform\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import Input, Add, Activation, ZeroPadding2D, AveragePooling2D\n",
    "from tensorflow.keras.layers import Conv2D, Dense, Flatten, MaxPooling2D, Dropout, BatchNormalization\n",
    "\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eef72732",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset Directory\n",
    "DIRECTORY = r'skin-lesions'\n",
    "\n",
    "# Dataset Directory\n",
    "#DIRECTORY = r'skin-lesions-HAM10000'\n",
    "\n",
    "# Dataset Directory\n",
    "#DIRECTORY = r'skin-lesions-ISIC2017'\n",
    "\n",
    "# Categories of Dataset\n",
    "CATEGORIES = ['melanoma', 'nevus', 'seborrheic_keratosis']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dfabbfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_SIZE = 224\n",
    "lesions_data = []\n",
    "\n",
    "for category in CATEGORIES:\n",
    "    \n",
    "    # Joins Categories to the Directory Folder\n",
    "    new_folder = os.path.join(DIRECTORY, category)\n",
    "    \n",
    "    # Assign Lables to Data Categories (0: melanoma, 1: nevus, 2: seborrheic_keratosis)\n",
    "    label = CATEGORIES.index(category)\n",
    "    \n",
    "    # Join Images with Relevant Category Folder\n",
    "    for img in os.listdir(new_folder):\n",
    "        img_path = os.path.join(new_folder, img)\n",
    "        \n",
    "        # Read Each Image as Array\n",
    "        img_array = cv2.imread(img_path)\n",
    "        \n",
    "        # Resize the Each Image to 256 x 256\n",
    "        img_array = cv2.resize(img_array, (IMAGE_SIZE, IMAGE_SIZE))\n",
    "      \n",
    "        # Combine all the Images and Labels in a Single Directory\n",
    "        lesions_data.append([img_array, label])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e1be995",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(lesions_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b450d518",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot a Bar Chart to Show Total Images in Each Class\n",
    "\n",
    "plot_list = []\n",
    "\n",
    "for i in lesions_data:\n",
    "    if(i[1] == 0):\n",
    "        plot_list.append(\"Melanoma\")\n",
    "    elif(i[1] == 1):\n",
    "        plot_list.append(\"Nevus\")\n",
    "    else:\n",
    "        plot_list.append(\"Seborrheic Keratosis\")\n",
    "        \n",
    "ax = sns.countplot(plot_list)\n",
    "plt.title(\"Total Images in Each Class\")\n",
    "for p in ax.patches:\n",
    "   ax.annotate('{:.0f}'.format(p.get_height()), (p.get_x()+0.25, p.get_height()+0.01))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e803c231",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pie Chart to Show the Porportion of Each Class\n",
    "\n",
    "# Count occurrences of each category\n",
    "counts = {}\n",
    "\n",
    "for category in plot_list:\n",
    "    counts[category] = counts.get(category, 0) + 1\n",
    "\n",
    "# Prepare data for the pie chart\n",
    "categories = counts.keys()\n",
    "category_counts = counts.values()\n",
    "\n",
    "# Create the pie chart\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.pie(category_counts, labels=categories, autopct='%1.1f%%')\n",
    "plt.axis('equal')  # Equal aspect ratio ensures that pie is drawn as a circle\n",
    "plt.title('Skin Lesions Distribution')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40907a3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract Features and Labels of Data\n",
    "\n",
    "X = []\n",
    "y = []\n",
    "\n",
    "for features, labels in lesions_data:\n",
    "    X.append(features)\n",
    "    y.append(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18523971",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aad9b24b",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57665927",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert Features into Array \n",
    "\n",
    "X = np.array(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e601b03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Features Sahpe\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f89e4f1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert Labels into Array\n",
    "\n",
    "y = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7caf4d65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Labels Shape\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f75f1e36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of all Primary Lables\n",
    "np.unique(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36856dcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "# Define the number of folds\n",
    "k = 5\n",
    "\n",
    "# Create a StratifiedKFold object to perform k-fold cross-validation\n",
    "kf = StratifiedKFold(n_splits=k, shuffle=True, random_state=42)\n",
    "\n",
    "# Initialize a list to store the performance metrics for each fold\n",
    "fold_metrics = []\n",
    "\n",
    "# Iterate over each fold\n",
    "for train_index, val_index in kf.split(X, y):\n",
    "    \n",
    "    # Split the data into training and validation sets for the current fold\n",
    "    X_train, X_val = X[train_index], X[val_index]\n",
    "    y_train, y_val = y[train_index], y[val_index]\n",
    "\n",
    "    # Proposed SkinLesNet CNN Model\n",
    "\n",
    "    model = Sequential()\n",
    "\n",
    "    # 1st Convolutional Input Layer\n",
    "    model.add(Conv2D(32, (3,3), activation='relu', input_shape=(256, 256, 3)))\n",
    "    model.add(MaxPooling2D((2,2)))\n",
    "\n",
    "    # 3rd Convolutional Layer\n",
    "    model.add(Conv2D(64, (3,3), activation='relu'))\n",
    "    model.add(MaxPooling2D((2,2)))\n",
    "\n",
    "    # 3rd Convolutional Layer\n",
    "    model.add(Conv2D(128, (3,3), activation='relu'))\n",
    "    model.add(MaxPooling2D((2,2)))\n",
    "\n",
    "    # Flatten Layer \n",
    "    model.add(Flatten())\n",
    "\n",
    "    # Hidden Layer\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "\n",
    "    # Output layer\n",
    "    model.add(Dense(3, activation='softmax'))\n",
    "    \n",
    "    # Compiling the Sequential Model\n",
    "\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=0.001, ema_momentum=0.99)\n",
    "\n",
    "    model.compile(loss='sparse_categorical_crossentropy',  optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "    # Train the model\n",
    "    model.fit(X_train, y_train, epochs=10, batch_size=32, verbose=1)\n",
    "\n",
    "    # Evaluate the model on the validation set\n",
    "    metrics = model.evaluate(X_val, y_val)\n",
    "\n",
    "    # Store the metrics for the current fold\n",
    "    fold_metrics.append(metrics)\n",
    "\n",
    "# Calculate the average performance metrics across all folds\n",
    "avg_metrics = np.mean(fold_metrics, axis=0)\n",
    "print(\"Average Performance Metrics:\")\n",
    "print(\"Loss:\", avg_metrics[0])\n",
    "print(\"Accuracy:\", avg_metrics[1])\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db913e9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split Data into Train and Test Sets (80:20)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19a54faf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape Labels\n",
    "y_train = y_train.reshape(len(y_train), 1)\n",
    "y_test = y_test.reshape(len(y_test), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a9958ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Training Features: \", X_train.shape)\n",
    "print(\"Testing Features: \", X_test.shape)\n",
    "\n",
    "print(\"Training Labels: \", y_train.shape)\n",
    "print(\"Testing Labels: \", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04d143b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot first 15 Images from Training Dataset\n",
    "\n",
    "# Define Rows and Columns for Subplot\n",
    "rows, columns = 5, 5\n",
    "\n",
    "# Define Figure Size\n",
    "fig=plt.figure(figsize=(12, 12))\n",
    "\n",
    "# Visualize Random Images\n",
    "for i in range(1, 15 +1):\n",
    "    \n",
    "    fig.add_subplot(rows, columns, i)\n",
    "    \n",
    "    plt.imshow(X_train[i-1])\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    \n",
    "    # Define Labels\n",
    "    if y_train[i-1] == 0:\n",
    "        label_name = \"Melanoma\"\n",
    "    elif y_train[i-1] == 1:\n",
    "        label_name = \"Nevus\"\n",
    "    else:\n",
    "        label_name = \"Seborrheic Keratosis\"\n",
    "    plt.title(\"{}\"\n",
    "          .format(label_name))\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "246ce623",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rescale Images to Normalize Pixel Values (0 - 255)\n",
    "\n",
    "X_train = X_train.astype('float32')/255.0\n",
    "X_test  = X_test.astype('float32')/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5654f737",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fcbd455",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ff7e334",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Any Random Image from Training Data\n",
    "\n",
    "idx = random.randint(0, len(X_train))\n",
    "plt.imshow(X_train[idx, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1387cb1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "# Proposed SkinLesNet CNN Model\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "# 1st Convolutional Input Layer\n",
    "model.add(Conv2D(32, kernel_size=(3,3), padding='same', activation='relu', input_shape=(256, 256, 3)))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "# 2nd Convolutional Layer\n",
    "model.add(Conv2D(32, kernel_size=(3,3), padding='same', activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "# 3rd Convolutional Layer\n",
    "model.add(Conv2D(64, kernel_size=(3,3), padding='same', activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "# 4th Convolutional Layers\n",
    "model.add(Conv2D(128, kernel_size=(3,3), padding='same', activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "# Flatten Layer \n",
    "model.add(Flatten())\n",
    "\n",
    "# Hidden Layer\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "# Output layer\n",
    "model.add(Dense(3, activation='softmax'))\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4f01479",
   "metadata": {},
   "source": [
    "# SkinLesNet Proposed Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "279b806e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Proposed SkinLesNet CNN Model\n",
    "\n",
    "start = datetime.datetime.now()\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "# 1st Convolutional Input Layer\n",
    "model.add(Conv2D(32, (3,3), activation='relu', input_shape=(IMAGE_SIZE, IMAGE_SIZE, 3)))\n",
    "model.add(MaxPooling2D((2,2)))\n",
    "\n",
    "# 2nd Convolutional Input Layer\n",
    "model.add(Conv2D(64, (3,3), activation='relu'))\n",
    "model.add(MaxPooling2D((2,2)))\n",
    "\n",
    "# 3rd Convolutional Layer\n",
    "model.add(Conv2D(64, (3,3), activation='relu'))\n",
    "model.add(MaxPooling2D((2,2)))\n",
    "\n",
    "# 4th Convolutional Layer\n",
    "model.add(Conv2D(128, (3,3), activation='relu'))\n",
    "model.add(MaxPooling2D((2,2)))\n",
    "\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "# Flatten Layer \n",
    "model.add(Flatten())\n",
    "\n",
    "# Hidden Layer\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "# Output layer\n",
    "model.add(Dense(3, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4445830",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Display Model Summary\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4297cf6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model(model, to_file='SkimLesNet.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77058017",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "# Create an ImageDataGenerator instance for data augmentation\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=10,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True\n",
    ")\n",
    "\n",
    "# Create a data generator for the training set with data augmentation\n",
    "train_datagen = datagen.flow(X_train, y_train, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# Create a separate data generator for the test set without data augmentation\n",
    "test_datagen = ImageDataGenerator().flow(X_test, y_test, batch_size=batch_size)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Train the model using data augmentation\n",
    "model.fit(train_datagen,\n",
    "          epochs=10,\n",
    "          steps_per_epoch=len(X_train) // batch_size,\n",
    "          validation_data=test_datagen,\n",
    "          validation_steps=len(X_test) // batch_size)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6377df18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compiling the Sequential Model\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001, ema_momentum=0.99)\n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy',  optimizer=optimizer, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb695ac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training the Model for 10 Epochs\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 10\n",
    "\n",
    "history = model.fit(X_train, y_train, batch_size=BATCH_SIZE, epochs=EPOCHS, verbose=1, \n",
    "                    validation_data=(X_test, y_test))\n",
    "\n",
    "(eval_loss, eval_acc) = model.evaluate(X_test, y_test, batch_size=BATCH_SIZE, verbose=1)\n",
    "\n",
    "print('\\n[INFO] Accuracy: {:.2f}%'.format(eval_acc * 100)) \n",
    "print('[INFO] Loss: {}'.format(eval_loss))\n",
    "\n",
    "end= datetime.datetime.now()\n",
    "elapsed= end-start\n",
    "\n",
    "print ('Time: ', elapsed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f50ef121",
   "metadata": {},
   "outputs": [],
   "source": [
    "h = history.history\n",
    "h.keys()\n",
    "\n",
    "plt.figure(figsize=(8,5))\n",
    "\n",
    "#plt.subplot(2, 2, 1)\n",
    "plt.plot(h['accuracy'], label=\"Training Accuracy\")\n",
    "plt.plot(h['val_accuracy'], label=\"Validaion Accuracy\")\n",
    "plt.legend(loc='upper left')\n",
    "#plt.title(\"Training vs Validation Accuracy\")\n",
    "\n",
    "#plt.subplot(2, 2, 2)\n",
    "plt.plot(h['loss'], label=\"Training Loss\")\n",
    "plt.plot(h['val_loss'], label=\"Validation Loss\")\n",
    "plt.legend(loc='upper right')\n",
    "#plt.title(\"Training vs Validation Loss\")\n",
    "\n",
    "plt.title(\"Model Accuracy\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef1a081d",
   "metadata": {},
   "outputs": [],
   "source": [
    "(_, test_acc) = model.evaluate(X_test, y_test, batch_size=BATCH_SIZE, verbose=1)\n",
    "(_, train_acc) = model.evaluate(X_train, y_train, batch_size=BATCH_SIZE, verbose=1)\n",
    "\n",
    "print('\\nTraining Accuracy: {:.2f}%'.format(train_acc * 100)) \n",
    "print('Testing Accuracy: {:.2f}%'.format(test_acc * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81c0a386",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d7b9b0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c939604d",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_classes = np.argmax(y_pred, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d74f1fa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8947a310",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_names = ['melanoma', 'nevus', 'seborrheic keratosis']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f59a83b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, predict_classes, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4358ee0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_test, predict_classes)\n",
    "\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99bc60e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7,5))\n",
    "\n",
    "plt.title('Confusion Matrix')\n",
    "\n",
    "sns.heatmap(cm, annot=True, cmap='flare', fmt='d', xticklabels=target_names, yticklabels=target_names)\n",
    "\n",
    "plt.xlabel('Predicted Labels')\n",
    "plt.ylabel('True Labels')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a4f649d",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx2 = random.randint(0, len(y_test))\n",
    "\n",
    "test_img = X_test[idx2, :]\n",
    "test_label = y_test[idx2]\n",
    "\n",
    "y_pred = model.predict(X_test[idx2,:].reshape(1, IMAGE_SIZE, IMAGE_SIZE, 3))\n",
    "\n",
    "y_pred = np.argmax(y_pred)\n",
    "\n",
    "if (y_pred == 0):\n",
    "    pred = 'Melanoma'\n",
    "elif (y_pred == 1):\n",
    "    pred = 'Nevus'\n",
    "else:\n",
    "    pred = 'Seborrheic Keratosis'\n",
    "\n",
    "    \n",
    "if (test_label == 0):\n",
    "    plt.title(\"Actual Image: Melanoma\" +\"\\nModel Prediction: \" + str(pred))\n",
    "elif (test_label == 1):\n",
    "    plt.title(\"Actual Image: Nevus\" +\"\\nModel Prediction: \" + str(pred))\n",
    "else:\n",
    "    plt.title(\"Actual Image: Seborrheic Keratosis\" +\"\\nModel Prediction: \" + str(pred))\n",
    "    \n",
    "plt.imshow(test_img)\n",
    "\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02958ab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('model_skin.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cee80806",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "# wrap our model into a scikit-learn compatible classifier\n",
    "print(\"[INFO] initializing model...\")\n",
    "\n",
    "model_fine = KerasClassifier(build_fn=model, verbose=0)\n",
    "\n",
    "params={'batch_size':[100, 20, 50, 25, 32],  \n",
    "        'nb_epoch':[200, 100, 300, 400], \n",
    "           \n",
    "        } \n",
    "gs=GridSearchCV(estimator=model_fine, param_grid=params, cv=10) \n",
    "\n",
    "# now fit the dataset to the GridSearchCV object.  \n",
    "gs = gs.fit(X_train, y_train)\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10e8ba85",
   "metadata": {},
   "source": [
    "# Identity Block Inside ResNet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7e19bc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def identity_block(X, f, filters, stage, block):\n",
    "    \"\"\"\n",
    "    Implementation of the identity block as defined in Figure   \n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    X : tensor\n",
    "        input tensor of shape (m, n_H_prev, n_W_prev, n_C_prev)\n",
    "    f : integer\n",
    "        specifying the shape of the middle CONV's window for the main path\n",
    "    filters : list\n",
    "        python list of integers, defining the number of filters in the CONV layers of the main path\n",
    "    stage : integer\n",
    "        used to name the layers, depending on their position in the network\n",
    "    block : str\n",
    "        used to name the layers, depending on their position in the network\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    X : tensor\n",
    "        output of the identity block, tensor of shape (n_H, n_W, n_C)\n",
    "    \"\"\"\n",
    "\n",
    "    # defining name basis\n",
    "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
    "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
    "\n",
    "    # Retrieve Filters\n",
    "    F1, F2, F3 = filters\n",
    "\n",
    "    # Save the input value. we'll need this later to add back to the main path. \n",
    "    X_shortcut = X\n",
    "\n",
    "    # First component of main path\n",
    "    X = Conv2D(filters=F1, kernel_size=(1, 1), strides=(1, 1), padding='valid', \n",
    "               name=conv_name_base + '2a', kernel_initializer=glorot_uniform(seed=0))(X)\n",
    "    X = BatchNormalization(axis=3, name=bn_name_base + '2a')(X)\n",
    "    X = Activation('relu')(X)\n",
    "\n",
    "    # Second component of main path\n",
    "    X = Conv2D(filters=F2, kernel_size=(f, f), strides=(1, 1), padding='same', \n",
    "               name=conv_name_base + '2b', kernel_initializer=glorot_uniform(seed=0))(X)\n",
    "    X = BatchNormalization(axis=3, name=bn_name_base + '2b')(X)\n",
    "    X = Activation('relu')(X)\n",
    "\n",
    "    # Third component of main path\n",
    "    X = Conv2D(filters=F3, kernel_size=(1, 1), strides=(1, 1), padding='valid', \n",
    "               name=conv_name_base + '2c', kernel_initializer=glorot_uniform(seed=0))(X)\n",
    "    X = BatchNormalization(axis=3, name=bn_name_base + '2c')(X)\n",
    "\n",
    "    # Final step: Add shortcut value to main path, and pass it through a RELU activation\n",
    "    X = Add()([X, X_shortcut])\n",
    "    X = Activation('relu')(X)\n",
    "\n",
    "    return X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f622da8a",
   "metadata": {},
   "source": [
    "# Convolutional Block in ResNet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eba00d65",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convolutional_block(X, f, filters, stage, block, s=2):\n",
    "    \"\"\"\n",
    "    Implementation of the convolutional block as defined in Figure   \n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    X : tensor\n",
    "        input tensor of shape (m, n_H_prev, n_W_prev, n_C_prev)\n",
    "    f : integer\n",
    "        specifying the shape of the middle CONV's window for the main path\n",
    "    filters : list\n",
    "        python list of integers, defining the number of filters in the CONV layers of the main path\n",
    "    stage : integer\n",
    "        used to name the layers, depending on their position in the network\n",
    "    block : str\n",
    "        used to name the layers, depending on their position in the network\n",
    "    s : integer, optional\n",
    "        Integer, specifying the stride to be used. The default is 2.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    X : tensor\n",
    "        output of the convolutional block, tensor of shape (n_H, n_W, n_C)\n",
    "    \"\"\"\n",
    "\n",
    "    # defining name basis\n",
    "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
    "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
    "\n",
    "    # Retrieve Filters\n",
    "    F1, F2, F3 = filters\n",
    "\n",
    "    # Save the input value\n",
    "    X_shortcut = X\n",
    "\n",
    "    # First component of main path \n",
    "    X = Conv2D(filters=F1, kernel_size=(1, 1), strides=(s, s), padding='valid', name=conv_name_base + '2a', kernel_initializer=glorot_uniform(seed=0))(X)\n",
    "    X = BatchNormalization(axis=3, name=bn_name_base + '2a')(X)\n",
    "    X = Activation('relu')(X)\n",
    "\n",
    "    # Second component of main path (≈3 lines)\n",
    "    X = Conv2D(filters=F2, kernel_size=(f, f), strides=(1, 1), padding='same', name=conv_name_base + '2b', kernel_initializer=glorot_uniform(seed=0))(X)\n",
    "    X = BatchNormalization(axis=3, name=bn_name_base + '2b')(X)\n",
    "    X = Activation('relu')(X)\n",
    "\n",
    "    # Third component of main path (≈2 lines)\n",
    "    X = Conv2D(filters=F3, kernel_size=(1, 1), strides=(1, 1), padding='valid', name=conv_name_base + '2c', kernel_initializer=glorot_uniform(seed=0))(X)\n",
    "    X = BatchNormalization(axis=3, name=bn_name_base + '2c')(X)\n",
    "\n",
    "    ##### SHORTCUT PATH #### (≈2 lines)\n",
    "    X_shortcut = Conv2D(filters=F3, kernel_size=(1, 1), strides=(s, s), padding='valid', name=conv_name_base + '1', kernel_initializer=glorot_uniform(seed=0))(X_shortcut)\n",
    "    X_shortcut = BatchNormalization(axis=3, name=bn_name_base + '1')(X_shortcut)\n",
    "\n",
    "    # Final step: Add shortcut value to main path, and pass it through a RELU activation (≈2 lines)\n",
    "    X = Add()([X, X_shortcut])\n",
    "    X = Activation('relu')(X)\n",
    "\n",
    "    return X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14fd2006",
   "metadata": {},
   "source": [
    "# Implementing ResNet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16ddf28d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ResNet50(input_shape, outputClasses):\n",
    "    \"\"\"\n",
    "    Implementation of the popular ResNet50 the following architecture:\n",
    "    CONV2D -> BATCHNORM -> RELU -> MAXPOOL -> CONVBLOCK -> IDBLOCK*2 -> CONVBLOCK -> IDBLOCK*3\n",
    "    -> CONVBLOCK -> IDBLOCK*5 -> CONVBLOCK -> IDBLOCK*2 -> AVGPOOL -> TOPLAYER\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    input_shape : tuple, optional\n",
    "        shape of the input image. \n",
    "    outputClasses : integer, optional\n",
    "        number of classes. \n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    model : object\n",
    "        a Model() instance in Keras\n",
    "    \"\"\"\n",
    "    \n",
    "    # Define the input as a tensor with shape input_shape\n",
    "    X_input = Input(input_shape)\n",
    "\n",
    "    # Zero-Padding\n",
    "    X = ZeroPadding2D((3, 3))(X_input)\n",
    "\n",
    "    # Stage 1\n",
    "    X = Conv2D(64, (7, 7), strides=(2, 2), name='conv1', kernel_initializer=glorot_uniform(seed=0))(X)\n",
    "    X = BatchNormalization(axis=3, name='bn_conv1')(X)\n",
    "    X = Activation('relu')(X)\n",
    "    X = MaxPooling2D((3, 3), strides=(2, 2))(X)\n",
    "\n",
    "    # Stage 2\n",
    "    X = convolutional_block(X, f=3, filters=[64, 64, 256], stage=2, block='a', s=1)\n",
    "    X = identity_block(X, 3, [64, 64, 256], stage=2, block='b')\n",
    "    X = identity_block(X, 3, [64, 64, 256], stage=2, block='c')\n",
    "\n",
    "    # Stage 3 \n",
    "    X = convolutional_block(X, f=3, filters=[128, 128, 512], stage=3, block='a', s=2)\n",
    "    X = identity_block(X, 3, [128, 128, 512], stage=3, block='b')\n",
    "    X = identity_block(X, 3, [128, 128, 512], stage=3, block='c')\n",
    "    X = identity_block(X, 3, [128, 128, 512], stage=3, block='d')\n",
    "\n",
    "    # Stage 4\n",
    "    X = convolutional_block(X, f=3, filters=[256, 256, 1024], stage=4, block='a', s=2)\n",
    "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='b')\n",
    "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='c')\n",
    "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='d')\n",
    "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='e')\n",
    "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='f')\n",
    "\n",
    "    # Stage 5\n",
    "    X = convolutional_block(X, f=3, filters=[512, 512, 2048], stage=5, block='a', s=2)\n",
    "    X = identity_block(X, 3, [512, 512, 2048], stage=5, block='b')\n",
    "    X = identity_block(X, 3, [512, 512, 2048], stage=5, block='c')\n",
    "\n",
    "    # AVGPOOL \n",
    "    X = AveragePooling2D(pool_size=(2, 2), padding='same')(X)\n",
    "\n",
    "    # output layer\n",
    "    X = Flatten()(X)\n",
    "    X = Dense(outputClasses, activation='softmax', name='fc' + str(outputClasses), \n",
    "              kernel_initializer=glorot_uniform(seed=0))(X)\n",
    "\n",
    "    # Create model\n",
    "    model = Model(inputs=X_input, outputs=X, name='ResNet50')\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d856a0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_rn = ResNet50(input_shape=(IMAGE_SIZE, IMAGE_SIZE, 3), outputClasses=3)\n",
    "\n",
    "model_rn.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model_rn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5464728",
   "metadata": {},
   "outputs": [],
   "source": [
    "hist = model_rn.fit(X_train, y_train, epochs=EPOCHS, batch_size=BATCH_SIZE, verbose=1, \n",
    "                 validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24f7c850",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "resnet_initial = ResNet50V2(include_top= False)\n",
    "\n",
    "resnet_initial.trainable = False\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bdeb08f",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "inputs = Input(shape=(IMAGE_SIZE, IMAGE_SIZE, 3))\n",
    "\n",
    "x = resnet_initial(inputs)\n",
    "x = layers.GlobalAveragePooling2D()(x)\n",
    "x = layers.Dense(128, activation = \"relu\")(x)\n",
    "x = layers.Dropout(0.3)(x)\n",
    "x = layers.Dense(64, activation = \"relu\")(x)\n",
    "\n",
    "outputs = layers.Dense(3, activation=\"softmax\")(x)\n",
    "\n",
    "resnet_model = Model(inputs, outputs)\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cd81733",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "resnet_initial.trainable = True\n",
    "\n",
    "for layer in resnet_initial.layers[:-5]:\n",
    "    resnet_model.trainable = False\n",
    "\n",
    "resnet_model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e3c102d",
   "metadata": {},
   "outputs": [],
   "source": [
    "(_, test_acc) = model_rn.evaluate(X_test, y_test, batch_size=BATCH_SIZE, verbose=1)\n",
    "(_, train_acc) = model_rn.evaluate(X_train, y_train, batch_size=BATCH_SIZE, verbose=1)\n",
    "\n",
    "print('\\nTraining Accuracy: {:.2f}%'.format(train_acc * 100)) \n",
    "print('Testing Accuracy: {:.2f}%'.format(test_acc * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f37ecab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_resnet = model_rn.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b90c797b",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_classes_resnet = np.argmax(y_pred_resnet, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aecda618",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, predict_classes_resnet, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f12a9eed",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_test, predict_classes_resnet)\n",
    "\n",
    "plt.figure(figsize=(7,5))\n",
    "\n",
    "plt.title('Confusion Matrix')\n",
    "\n",
    "sns.heatmap(cm, annot=True, cmap='flare', fmt='d', xticklabels=target_names, yticklabels=target_names)\n",
    "\n",
    "plt.xlabel('Predicted Labels')\n",
    "plt.ylabel('True Labels')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49e4fab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "h = hist.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eac5aa71",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,5))\n",
    "\n",
    "#plt.subplot(2, 2, 1)\n",
    "plt.plot(h['accuracy'], label=\"Training Accuracy\")\n",
    "plt.plot(h['val_accuracy'], label=\"Validaion Accuracy\")\n",
    "plt.legend(loc='upper left')\n",
    "#plt.title(\"Training vs Validation Accuracy\")\n",
    "\n",
    "#plt.subplot(2, 2, 2)\n",
    "plt.plot(h['loss'], label=\"Training Loss\")\n",
    "plt.plot(h['val_loss'], label=\"Validation Loss\")\n",
    "plt.legend(loc='upper right')\n",
    "#plt.title(\"Training vs Validation Loss\")\n",
    "\n",
    "plt.title(\"Model Accuracy\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bbb4a74",
   "metadata": {},
   "source": [
    "# VGG16 Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c3c1c24",
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg_initial = VGG16(input_shape=(IMAGE_SIZE, IMAGE_SIZE, 3), weights='imagenet', include_top=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9b2a09a",
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg_initial.trainable = False\n",
    "inputs = Input(shape=(IMAGE_SIZE, IMAGE_SIZE, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9140117f",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = vgg_initial(inputs, training=False)\n",
    "x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
    "x = layers.Dense(128, activation = \"relu\")(x)\n",
    "x = layers.Dropout(0.3)(x)\n",
    "x = layers.Dense(64, activation = \"relu\")(x)\n",
    "\n",
    "outputs = layers.Dense(3, activation=\"softmax\")(x)\n",
    "\n",
    "vgg_model = Model(inputs, outputs)\n",
    "vgg_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abedf76e",
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg_initial.trainable = True\n",
    "\n",
    "for layer in vgg_initial.layers[:-5]:\n",
    "    vgg_model.trainable = False\n",
    "\n",
    "# Make sure you have frozen the correct layers\n",
    "for i, layer in enumerate(vgg_model.layers):\n",
    "    print(i, layer.name, layer.trainable)\n",
    "    \n",
    "vgg_model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68e4a53d",
   "metadata": {},
   "outputs": [],
   "source": [
    "hist = vgg_model.fit(X_train, y_train, epochs=EPOCHS, batch_size=BATCH_SIZE, verbose=1, \n",
    "                 validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e910c31",
   "metadata": {},
   "outputs": [],
   "source": [
    "(_, test_acc) = vgg_model.evaluate(X_test, y_test, batch_size=BATCH_SIZE, verbose=1)\n",
    "(_, train_acc) = vgg_model.evaluate(X_train, y_train, batch_size=BATCH_SIZE, verbose=1)\n",
    "\n",
    "print('\\nTraining Accuracy: {:.2f}%'.format(train_acc * 100)) \n",
    "print('Testing Accuracy: {:.2f}%'.format(test_acc * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7650da7",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_vgg = vgg_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99a5a697",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_classes_vgg = np.argmax(y_pred_vgg, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20bcc1d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, predict_classes_vgg, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a110cb9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_test, predict_classes_vgg)\n",
    "\n",
    "plt.figure(figsize=(7,5))\n",
    "\n",
    "plt.title('Confusion Matrix')\n",
    "\n",
    "sns.heatmap(cm, annot=True, cmap='flare', fmt='d', xticklabels=target_names, yticklabels=target_names)\n",
    "\n",
    "plt.xlabel('Predicted Labels')\n",
    "plt.ylabel('True Labels')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8323220",
   "metadata": {},
   "outputs": [],
   "source": [
    "h = hist.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aef07777",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,5))\n",
    "\n",
    "#plt.subplot(2, 2, 1)\n",
    "plt.plot(h['accuracy'], label=\"Training Accuracy\")\n",
    "plt.plot(h['val_accuracy'], label=\"Validaion Accuracy\")\n",
    "plt.legend(loc='upper left')\n",
    "#plt.title(\"Training vs Validation Accuracy\")\n",
    "\n",
    "#plt.subplot(2, 2, 2)\n",
    "plt.plot(h['loss'], label=\"Training Loss\")\n",
    "plt.plot(h['val_loss'], label=\"Validation Loss\")\n",
    "plt.legend(loc='upper right')\n",
    "#plt.title(\"Training vs Validation Loss\")\n",
    "\n",
    "plt.title(\"Model Accuracy\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5759ac3d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
